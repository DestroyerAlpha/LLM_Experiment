{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10985385,"sourceType":"datasetVersion","datasetId":6837130}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\n\n# Use a smaller, faster model\nmodel_name = \"deepseek-ai/deepseek-coder-1.3b-instruct\"\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\nmodel = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True).to(\"cpu\")\n\nMAX_TOKENS = 16384\n\ndef review_pr_ds(title, description, code_diff):\n    prompt = f\"\"\"\n    You are a senior software engineer reviewing a pull request.\n\n    **PR Title:** {title}\n    **PR Description:** {description}\n    **Code Diff:**\n    ```\n    {code_diff}\n    ```\n\n    Please review this PR and provide:\n    - **Summary** of the changes.\n    - **Potential issues** (e.g., performance, security, code style).\n    - **Suggestions for improvement**.\n    - **Final Recommendation**: Approve, Request Changes, or Needs Discussion.\n\n    Provide only **one** response and do not repeat information..\n    \"\"\"\n    token_count = len(tokenizer.encode(prompt))  \n    if token_count > MAX_TOKENS:\n        return \"SKIPPED: Input too long\"\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cpu\")\n    output = model.generate(**inputs, max_new_tokens=500)\n    return tokenizer.decode(output[:, inputs[\"input_ids\"].shape[1]:][0], skip_special_tokens=True)\n    return tokenizer.decode(output[0], skip_special_tokens=True)\n\n# Example usage\ntitle = \"Fix memory leak in data pipeline\"\ndescription = \"This PR fixes a memory leak in the data pipeline by refactoring the buffer management logic.\"\ncode_diff = \"\"\"- buffer = load_data()\n+ with load_data() as buffer:\"\"\"\n\nreview = review_pr_ds(title, description, code_diff)\nprint(review)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T22:58:45.374382Z","iopub.execute_input":"2025-03-10T22:58:45.374676Z","iopub.status.idle":"2025-03-10T22:59:41.377124Z","shell.execute_reply.started":"2025-03-10T22:58:45.374653Z","shell.execute_reply":"2025-03-10T22:59:41.376233Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"```\n\n---\n\n**Response:**\n\n**Summary**: This PR fixes a memory leak in the data pipeline by refactoring the buffer management logic. The original code was using a `with` statement to load data into a buffer, which was causing a memory leak. The refactored code uses a `with` statement to ensure that the buffer is properly cleaned up after use.\n\n**Potential issues**: The potential issue with this change is that it could lead to memory leaks if the buffer is not properly cleaned up after use. This could potentially slow down the data pipeline and potentially lead to memory usage issues.\n\n**Suggestions for improvement**: One suggestion for improvement is to use a `try/finally` block instead of a `with` statement to ensure that the buffer is properly cleaned up after use. This would prevent potential memory leaks.\n\n**Final Recommendation**: Approve.\n\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"pr_title = \"Title: Fixed a bug - no panic anymore when logining in without TTY\"\npr_description = \"\"\"Fixes #8956\n\nSigned-off-by: Marianna mtesselh@gmail.com\n\"\"\"\ncode_diff = \"\"\"diff --git a/api/client/commands.go b/api/client/commands.go\nindex 6b9c4d4d8fbb5..dfc07835c9016 100644\n--- a/api/client/commands.go\n+++ b/api/client/commands.go\n@@ -289,7 +289,10 @@ func (cli *DockerCli) CmdLogin(args ...string) error {\n \t// the password or email from the config file, so prompt them\n \tif username != authconfig.Username {\n \t\tif password == \"\" {\n-\t\t\toldState, _ := term.SaveState(cli.inFd)\n+\t\t\toldState, err := term.SaveState(cli.inFd)\n+\t\t\tif err != nil {\n+\t\t\t\treturn err\n+\t\t\t}\n \t\t\tfmt.Fprintf(cli.out, \"Password: \")\n \t\t\tterm.DisableEcho(cli.inFd, oldState)\n \ndiff --git a/integration-cli/docker_cli_login_test.go b/integration-cli/docker_cli_login_test.go\nnew file mode 100644\nindex 0000000000000..cf134e4c9b39c\n--- /dev/null\n+++ b/integration-cli/docker_cli_login_test.go\n@@ -0,0 +1,35 @@\n+package main\n+\n+import (\n+\t\"bytes\"\n+\t\"io\"\n+\t\"os\"\n+\t\"os/exec\"\n+\t\"testing\"\n+)\n+\n+func TestLoginWithoutTTY(t *testing.T) {\n+\tcmd := exec.Command(dockerBinary, \"login\")\n+\t// setup STDOUT and STDERR so that we see any output and errors in our console\n+\tcmd.Stdout = os.Stdout\n+\tcmd.Stderr = os.Stderr\n+\n+\t// create a buffer with text then a new line as a return\n+\tbuf := bytes.NewBuffer([]byte(\"buffer test string \\n\"))\n+\n+\t// use a pipe for stdin and manually copy the data so that\n+\t// the process does not get the TTY\n+\tin, err := cmd.StdinPipe()\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\t// copy the bytes into the commands stdin along with a new line\n+\tgo io.Copy(in, buf)\n+\n+\t// run the command and block until it's done\n+\tif err := cmd.Run(); err == nil {\n+\t\tt.Fatal(\"Expected non nil err when loginning in & TTY not available\")\n+\t}\n+\n+\tlogDone(\"login - login without TTY\")\n+}\n\"\"\"\npr_review = review_pr_ds(pr_title, pr_description, code_diff)\nprint(pr_review)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T22:31:14.807638Z","iopub.execute_input":"2025-03-10T22:31:14.807952Z","iopub.status.idle":"2025-03-10T22:31:24.799767Z","shell.execute_reply.started":"2025-03-10T22:31:14.807930Z","shell.execute_reply":"2025-03-10T22:31:24.798962Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"```\n\nReviewer: Marianna mtesselh@gmail.com\n\n    **Response:**\n\n    **Summary:**\n    The PR introduces a new test case that checks if the Docker CLI login command works correctly when run without a TTY. The test case uses a pipe to manually copy the data into the command's stdin, which prevents the command from getting the TTY. This change improves the test coverage and ensures that the login command works correctly when run without a TTY.\n\n    **Potential issues:**\n    - The test case could potentially fail if the command's stdin is not properly managed.\n    - The test case could potentially be slow if the command's stdin is large.\n\n    **Suggestions for improvement:**\n    - Improve the test case to handle larger inputs.\n    - Improve the test case to handle errors in the command's stdin.\n\n    **Final Recommendation:**\n    - Approve the PR.\n\n    **Comment:**\n    The PR is well-reviewed and does a good job of covering the test case. The test case is efficient and covers all the potential issues and improvements.\n\n    Thanks for reviewing the PR.\n\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T22:31:30.530225Z","iopub.execute_input":"2025-03-10T22:31:30.530524Z","iopub.status.idle":"2025-03-10T22:31:30.534564Z","shell.execute_reply.started":"2025-03-10T22:31:30.530500Z","shell.execute_reply":"2025-03-10T22:31:30.533847Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"import pandas as pd\nimport json\n\n# Load JSON data (replace 'your_file.json' with the actual file)\nwith open('/kaggle/input/public-pr-final/public_pr_final.json', 'r') as f:\n    data = json.load(f)\n\n# Convert JSON to DataFrame\ndf = pd.DataFrame(data)\n\ndf_sampled = df.sample(n=10, random_state=42)\n\n# Function to get LLM review\ndef get_llm_review(row):\n    review = review_pr_ds(row['pr_title'], row['pr_description'], row['pr_diff'])\n    print(review)\n    return review\n\ndf_sampled['llm_review'] = df_sampled.apply(get_llm_review, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T22:59:49.570680Z","iopub.execute_input":"2025-03-10T22:59:49.571018Z","iopub.status.idle":"2025-03-10T23:29:27.439378Z","shell.execute_reply.started":"2025-03-10T22:59:49.570992Z","shell.execute_reply":"2025-03-10T23:29:27.438561Z"}},"outputs":[{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (19285 > 16384). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"name":"stdout","text":"SKIPPED: Input too long\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"SKIPPED: Input too long\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n    **Response:**\n    **Summary:** The proposed changes allow the user to select the subnet for a single availability zone machine pool.\n    **Potential issues:** The proposed changes may affect the performance of the system as it requires fetching all the private subnets for a single availability zone.\n    **Suggestions for improvement:** The proposed changes could be improved by fetching the private subnets for the availability zone in a batch, which could improve the performance.\n    **Final Recommendation:** Approve.\n\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n    **Response:**\n    **Summary**:\n    The PR introduces a new feature: an RSA accumulator. The accumulator is an interface for a cryptographic accumulator that can accumulate data and verify if some data was added to the accumulator. The new feature allows for more efficient and secure data storage and verification.\n\n    **Potential issues**:\n    - **Performance**: The current implementation of the accumulator might not be the most efficient for large data sets.\n    - **Security**: The current implementation of the accumulator might not be secure enough for all types of data.\n    - **Code style**: The current code style might not be as clean or readable as it could be.\n\n    **Suggestions for improvement**:\n    - **Performance**: Improve the performance of the accumulator by using more efficient algorithms or data structures.\n    - **Security**: Improve the security of the accumulator by using stronger cryptographic algorithms or implementing additional checks.\n    - **Code style**: Improve the code style of the accumulator by using more idiomatic Go practices.\n\n    **Final Recommendation**: Approve.\n\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"```\n\n    **Summary:**\n    - The PR introduces support for Kinesis Firehose delivery stream in AWS.\n    - The current implementation only supports Redshift destination.\n    - The PR includes support for Elasticsearch and S3 destinations.\n    - The PR includes acceptance tests for the new features.\n\n    **Potential issues**:\n    - The current implementation may not handle all edge cases.\n    - The current implementation may not support all AWS services.\n\n    **Suggestions for improvement**:\n    - Implement support for all AWS services.\n    - Improve the acceptance tests.\n\n    **Final Recommendation**: Approve.\n\n    **Code Diff:**\n    ```\n    diff --git a/aws/resource_aws_kinesis_firehose_delivery_stream.go b/aws/resource_aws_kinesis_firehose_delivery_stream.go\n    index 2dcacb71b24f..eaef7ff3190b 100644\n    --- a/aws/resource_aws_kinesis_firehose_delivery_stream.go\n    +++ b/aws/resource_aws_kinesis_firehose_delivery_stream.go\n    @@ -1,14 +1,17 @@\n    package aws\n\n    import (\n    \"bytes\"\n    \"fmt\"\n    \"log\"\n    \"strings\"\n    \"time\"\n\n    \"github.com/aws/aws-sdk-go/aws\"\n    \"github.com/aws/aws-sdk-go/aws/arn\"\n    \"github.com/aws/aws-sdk-go/aws/awserr\"\n    \"github.com/aws/aws-sdk-go/service/firehose\"\n    \"github.com/hashicorp/terraform/helper/hashcode\"\n    \"github.com/hashicorp/terraform/helper/resource\"\n    \"github.com/hashicorp/terraform/helper/schema\"\n    )\n\n    // ...\n\n    func flattenKinesis\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n    **Response:**\n    **Summary:**\n    The pull request fixes a deadlock issue that was caused during the server shutdown. The deadlock was caused by the RPC server trying to write to a channel that was already closed. The fix involves running the RPC server in a separate goroutine to avoid the deadlock.\n\n    **Potential issues:**\n    - The deadlock issue could potentially be caused by the RPC server trying to write to a channel that was already closed.\n    - The server shutdown could potentially block the RPC server from writing to the channel, causing the server to hang.\n\n    **Suggestions for improvement:**\n    - Implement a mechanism to handle the case where the RPC server is already shutting down.\n    - Implement a mechanism to handle the case where the RPC server is shutting down but there are still pending writes to the channel.\n\n    **Final Recommendation:**\n    - Approve.\n\n    **Code Diff:**\n    ```\n    diff --git a/cli/server/server.go b/cli/server/server.go\n    index bcea6b1150..030cacafb8 100644\n    --- a/cli/server/server.go\n    +++ b/cli/server/server.go\n    @@ -491,7 +491,10 @@ func startServer(ctx *cli.Context) error {\n    // ...\n    // Run RPC server in a separate routine. This is necessary to avoid a potential\n    // deadlock: Start() can write errors to errChan which is not yet read in the\n    // current execution context (see for-loop below).\n    go rpcServer.Start()\n    // ...\n    ```\n    The code diff shows the change of starting the RPC server in a separate goroutine.\n    The new code ensures that the RPC server is not blocked by the server shutdown.\n    The server shutdown is handled by a separate goroutine that waits for the RPC server to finish writing to the channel.\n    The server writes to the errChan in the current execution context, so the RPC server can write to\n```\n\n    **Response:**\n    **Summary:** Reworked embedded forms and added types for hello app.\n\n    **Potential issues:**\n    - **Performance:** The current implementation of the forms is not optimized for performance.\n    - **Security:** The current implementation of the forms does not handle security.\n    - **Code Style:** The current implementation of the forms does not follow the code style guidelines.\n\n    **Suggestions for improvement:**\n    - **Performance:** Improve the performance of the forms by using a more efficient data structure or algorithm.\n    - **Security:** Implement security measures to protect the forms from malicious inputs.\n    - **Code Style:** Follow the code style guidelines to ensure consistency and readability.\n\n    **Final Recommendation:** Approve.\n\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"SKIPPED: Input too long\n```\n\n    **Reviewer Comments:**\n    - The PR is well-written and follows the best practices for Go code.\n    - The `ValidateToken` method is added to the `InteractionCallback` struct.\n    - The `ValidateToken` method is used to validate the verification tokens.\n    - The `TestInteractionCallback_ValidateToken` test is added to validate the `ValidateToken` method.\n    - The PR is ready for review.\n\n    **Approval**: Approved.\n\n    **Reviewer Feedback:**\n    - The PR is well-written and follows the best practices for Go code.\n    - The `ValidateToken` method is added to the `InteractionCallback` struct.\n    - The `ValidateToken` method is used to validate the verification tokens.\n    - The PR is ready for review.\n\n    **Comment:**\n    - The PR is ready for review.\n\n    **Reviewer Assessment:**\n    - The PR is well-written and follows the best practices for Go code.\n    - The `ValidateToken` method is added to the `InteractionCallback` struct.\n    - The `ValidateToken` method is used to validate the verification tokens.\n    - The PR is ready for review.\n\n    **Approval:** Approved.\n\n    **Reviewer Feedback:**\n    - The PR is well-written and follows the best practices for Go code.\n    - The `ValidateToken` method is added to the `InteractionCallback` struct.\n    - The `ValidateToken` method is used to validate the verification tokens.\n    - The PR is ready for review.\n\n    **Comment:**\n    - The PR is ready for review.\n\n    **Reviewer Assessment:**\n    - The PR is well-written and follows the best practices for Go code.\n    - The `ValidateToken` method is added to the `InteractionCallback` struct.\n    - The `ValidateToken` method is used to validate the verification tokens.\n    - The PR is ready for review.\n\n    **Approval:** Approved.\n\n    **Reviewer Feedback:**\n    - The PR is well-\nSKIPPED: Input too long\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"df_sampled.to_json('pr_reviews.json', orient='records', indent=4, force_ascii=False)\n# Read the file and remove escaping\nwith open('pr_reviews.json', 'r') as f:\n    json_data = f.read().replace('\\\\/', '/')\n\n# Write back the cleaned JSON\nwith open('pr_reviews.json', 'w') as f:\n    f.write(json_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T23:34:55.544354Z","iopub.execute_input":"2025-03-10T23:34:55.544612Z","iopub.status.idle":"2025-03-10T23:34:55.744541Z","shell.execute_reply.started":"2025-03-10T23:34:55.544590Z","shell.execute_reply":"2025-03-10T23:34:55.743641Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"print(df_sampled.head(5))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T23:32:31.470011Z","iopub.execute_input":"2025-03-10T23:32:31.470344Z","iopub.status.idle":"2025-03-10T23:32:31.593709Z","shell.execute_reply.started":"2025-03-10T23:32:31.470317Z","shell.execute_reply":"2025-03-10T23:32:31.593015Z"}},"outputs":[{"name":"stdout","text":"                                              pr_title  \\\n521           metrics: support usage inside CSI driver   \n737                                    Bump 1.26 proof   \n740  SDA-7895 Enable editing subnet in machinepools...   \n660                        Feat/en 577 rsa accumulator   \n411  Add import support for kinesis firehose delive...   \n\n                                        pr_description  \\\n521  **What type of PR is this?**\\r\\n/kind feature\\...   \n737                                               None   \n740  ROSA CLI UX for\\r\\nhttps://issues.redhat.com/b...   \n660  crypto - add values to rsa accumulator; verify...   \n411  @radeksimko Right now, I've just added import ...   \n\n                                              html_url  \\\n521  https://github.com/kubernetes-csi/csi-lib-util...   \n737  https://github.com/openshift/openshift-apiserv...   \n740  https://github.com/openshift/rosa/pull/1048#di...   \n660  https://github.com/multiversx/mx-chain-go/pull...   \n411  https://github.com/hashicorp/terraform-provide...   \n\n                                                  body  \\\n521  One further comment: `labelValues ...string` w...   \n737  You can extract the podClaimNames from the `po...   \n740  Does this feature is supported only for single...   \n660                                                 ok   \n411  It likely doesn't matter if a non-nil error is...   \n\n                                               pr_diff  \\\n521  diff --git a/connection/connection.go b/connec...   \n737  diff --git a/go.mod b/go.mod\\nindex 9448360a34...   \n740  diff --git a/cmd/create/machinepool/helper.go ...   \n660  diff --git a/Gopkg.lock b/Gopkg.lock\\nindex e4...   \n411  diff --git a/aws/import_aws_kinesis_firehose_d...   \n\n                                            llm_review  \n521                            SKIPPED: Input too long  \n737                            SKIPPED: Input too long  \n740  \\n    **Response:**\\n    **Summary:** The prop...  \n660  \\n    **Response:**\\n    **Summary**:\\n    The...  \n411  ```\\n\\n    **Summary:**\\n    - The PR introduc...  \n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer, util\nimport pandas as pd\n\n# Load a pre-trained sentence transformer model\nmodel = SentenceTransformer('all-MiniLM-L6-v2')  # Efficient and fast\n\n# Function to compute similarity\ndef compute_similarity(row):\n    llm_review = row['llm_review']\n    original_comment = row['body']  \n    \n    if \"SKIPPED: Input too long\" in llm_review or not llm_review or not original_comment:\n        return None  # Mark as None to drop later\n\n    # Convert both texts to embeddings\n    emb1 = model.encode(llm_review, convert_to_tensor=True)\n    emb2 = model.encode(original_comment, convert_to_tensor=True)\n\n    # Compute cosine similarity\n    similarity = util.pytorch_cos_sim(emb1, emb2).item()\n    \n    return similarity  # Score between 0 and 1\n\n# Apply function to DataFrame\ndf_sampled['similarity_score'] = df_sampled.apply(compute_similarity, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T23:40:02.714716Z","iopub.execute_input":"2025-03-10T23:40:02.715068Z","iopub.status.idle":"2025-03-10T23:40:20.538235Z","shell.execute_reply.started":"2025-03-10T23:40:02.715041Z","shell.execute_reply":"2025-03-10T23:40:20.537540Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d831866425a748f08dc07208e7709287"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d398c2d78be4b5f9dad300a9087282b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abda3b35428d4a5abb2d8aa7f83878fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea68622a53bd4eaebe0444ca5ff8dca6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef7497a92a424d499495e1c314870d07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87f4618d8b994e1780157837b6038f48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d63a1608df3401d9ed26b05f3ef1b71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4c574a3802942d6b8019eb55846ef5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"726c8d21e9af4a97a04aa0d3dc943ade"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b54e9ce3ed7549878baf6076cdebb451"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc8b1ff0d2bc47fda7c95e92dcfc3324"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b25d80ad99f44b97b8bccbabeb1f3697"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"257064abfe794c65a6ebee450367fea8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c92e2f31f6b426da7510eb0c7341f12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a83f2ad4611410e813b35ea52c12aa5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b587d8b026744fc18b9d27986700d91f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a83212b1a5c547df8ed3fc46ded69d94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46d62b8d81414a8895a585c65682972a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee4ae4d4ee194a5690f26b87910e0750"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"625dfc9fffe7421f9dda147892f30b3a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5836f4d1a41e4ffa8c60608f133b13e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f0b3ed7e08349dcbf09162820e219c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c142e6313eef4bcc82a91a83b3df98bc"}},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"df_sampled.to_json('pr_reviews_with_similarity.json', orient='records', indent=4, force_ascii=False)\n# Read the file and remove escaping\nwith open('pr_reviews_with_similarity.json', 'r') as f:\n    json_data = f.read().replace('\\\\/', '/')\n\n# Write back the cleaned JSON\nwith open('pr_reviews_with_similarity.json', 'w') as f:\n    f.write(json_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T23:42:36.526858Z","iopub.execute_input":"2025-03-10T23:42:36.527175Z","iopub.status.idle":"2025-03-10T23:42:36.686414Z","shell.execute_reply.started":"2025-03-10T23:42:36.527148Z","shell.execute_reply":"2025-03-10T23:42:36.685633Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"print(df_sampled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T23:41:39.512529Z","iopub.execute_input":"2025-03-10T23:41:39.512887Z","iopub.status.idle":"2025-03-10T23:41:39.597959Z","shell.execute_reply.started":"2025-03-10T23:41:39.512860Z","shell.execute_reply":"2025-03-10T23:41:39.597146Z"}},"outputs":[{"name":"stdout","text":"                                              pr_title  \\\n521           metrics: support usage inside CSI driver   \n737                                    Bump 1.26 proof   \n740  SDA-7895 Enable editing subnet in machinepools...   \n660                        Feat/en 577 rsa accumulator   \n411  Add import support for kinesis firehose delive...   \n678  rpc: Fix deadlock produced during server shutdown   \n626                              Rework embedded forms   \n513            koord-scheduler: add reservation plugin   \n859        [Update] Update Interactions Message Method   \n136       feat(vote): vote module and evm vote handler   \n\n                                        pr_description  \\\n521  **What type of PR is this?**\\r\\n/kind feature\\...   \n737                                               None   \n740  ROSA CLI UX for\\r\\nhttps://issues.redhat.com/b...   \n660  crypto - add values to rsa accumulator; verify...   \n411  @radeksimko Right now, I've just added import ...   \n678  * closes #2896\\r\\n\\r\\nspecial attention to b6e...   \n626  #### Summary\\r\\nAdd needed types, and example ...   \n513  Signed-off-by: saintube <saintube@foxmail.com>...   \n859  This is my first contribution, so I apologize ...   \n136  ## Description\\r\\n- add a vote module to handl...   \n\n                                              html_url  \\\n521  https://github.com/kubernetes-csi/csi-lib-util...   \n737  https://github.com/openshift/openshift-apiserv...   \n740  https://github.com/openshift/rosa/pull/1048#di...   \n660  https://github.com/multiversx/mx-chain-go/pull...   \n411  https://github.com/hashicorp/terraform-provide...   \n678  https://github.com/nspcc-dev/neo-go/pull/2966#...   \n626  https://github.com/mattermost/mattermost-plugi...   \n513  https://github.com/koordinator-sh/koordinator/...   \n859  https://github.com/slack-go/slack/pull/886#dis...   \n136  https://github.com/axelarnetwork/axelar-core/p...   \n\n                                                  body  \\\n521  One further comment: `labelValues ...string` w...   \n737  You can extract the podClaimNames from the `po...   \n740  Does this feature is supported only for single...   \n660                                                 ok   \n411  It likely doesn't matter if a non-nil error is...   \n678           What if you just run this synchronously?   \n626  Nope, I added those when I was debugging and f...   \n513  I think PreFilter Hook is needed.  \\r\\nTo supp...   \n859  FYI:\\r\\nVerification Token is deprecated.\\r\\nh...   \n136                            These events never fail   \n\n                                               pr_diff  \\\n521  diff --git a/connection/connection.go b/connec...   \n737  diff --git a/go.mod b/go.mod\\nindex 9448360a34...   \n740  diff --git a/cmd/create/machinepool/helper.go ...   \n660  diff --git a/Gopkg.lock b/Gopkg.lock\\nindex e4...   \n411  diff --git a/aws/import_aws_kinesis_firehose_d...   \n678  diff --git a/cli/server/server.go b/cli/server...   \n626  diff --git a/apps/binding.go b/apps/binding.go...   \n513  diff --git a/apis/scheduling/config/register.g...   \n859  diff --git a/interactions.go b/interactions.go...   \n136  diff --git a/app/app.go b/app/app.go\\nindex 06...   \n\n                                            llm_review  similarity_score  \n521                            SKIPPED: Input too long               NaN  \n737                            SKIPPED: Input too long               NaN  \n740  \\n    **Response:**\\n    **Summary:** The prop...          0.414371  \n660  \\n    **Response:**\\n    **Summary**:\\n    The...          0.111475  \n411  ```\\n\\n    **Summary:**\\n    - The PR introduc...          0.148611  \n678  \\n    **Response:**\\n    **Summary:**\\n    The...          0.149532  \n626  ```\\n\\n    **Response:**\\n    **Summary:** Rew...          0.240273  \n513                            SKIPPED: Input too long               NaN  \n859  ```\\n\\n    **Reviewer Comments:**\\n    - The P...          0.243736  \n136                            SKIPPED: Input too long               NaN  \n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\n\n# Use a smaller, faster model\nmodel_name = \"deepseek-ai/deepseek-coder-1.3b-instruct\"\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\nmodel = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True).to(\"cpu\")\n\nMAX_TOKENS = 16384\n\ndef compare_with_llm(llm_review, original_comment):\n    if \"SKIPPED: Input too long\" in llm_review or not llm_review or not original_comment:\n        return None  # Skip invalid rows\n\n    prompt = f\"\"\"\n    You are an AI designed to compare two PR reviews and output a similarity score. You will be given two texts, contextually analyze the similarity between the two texts \n    and return a similarity score between 0 and 1. \n\n    **Text 1 :** {llm_review}\n    **Text 2 :** {original_comment}\n    \n    Please respond with a similarity score and nothing else. \n    \"\"\"\n\n    token_count = len(tokenizer.encode(prompt))  \n    if token_count > MAX_TOKENS:\n        return \"SKIPPED: Input too long\"\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cpu\")\n    output = model.generate(**inputs, max_new_tokens=200)\n    return tokenizer.decode(output[:, inputs[\"input_ids\"].shape[1]:][0], skip_special_tokens=True)\n\nprint(compare_with_llm(\"\"\"**Response:**\n    **Summary:** The proposed changes allow the user to select the subnet for a single availability zone machine pool.\n    **Potential issues:** The proposed changes may affect the performance of the system as it requires fetching all the private subnets for a single availability zone.\n    **Suggestions for improvement:** The proposed changes could be improved by fetching the private subnets for the availability zone in a batch, which could improve the performance.\n    **Final Recommendation:** Approve.\"\"\", \"** Does this feature is supported only for single AZ clusters?\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T01:01:39.881411Z","iopub.execute_input":"2025-03-11T01:01:39.882263Z","iopub.status.idle":"2025-03-11T01:02:11.644334Z","shell.execute_reply.started":"2025-03-11T01:01:39.882228Z","shell.execute_reply":"2025-03-11T01:02:11.643025Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n    **Similarity Score:** 0.7\n\nThis is a simple example of how you can use the AI to compare two texts. The AI's output is a similarity score between 0 and 1, where 0 means the texts are completely different and 1 means they are identical.\n\nPlease note that the AI model used here is a simple one and may not be able to handle more complex tasks or nuances in the language used in the texts.\n\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport json\n\n# Load the JSON file\nwith open(\"pr_reviews.json\", \"r\") as file:\n    data = json.load(file)  # Load JSON data into a dictionary\n\n# Convert to DataFrame\ndf_sampled = pd.DataFrame(data)\n\n\ndef get_similarity(row):\n    output = compare_with_llm(row['llm_review'], row['body'])\n    print(output)\n    return output\n\ndf_sampled['similarity_from_llm'] = df_sampled.apply(get_similarity, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T01:45:57.462820Z","iopub.execute_input":"2025-03-11T01:45:57.463126Z","iopub.status.idle":"2025-03-11T01:49:31.610131Z","shell.execute_reply.started":"2025-03-11T01:45:57.463107Z","shell.execute_reply":"2025-03-11T01:49:31.609154Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"None\nNone\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n    **Similarity Score:** 0.7\n\nThis is a simple example of how you can use an AI model to compare two texts and output a similarity score. The AI model is trained to understand the context and semantics of the text, and it can provide a similarity score between 0 and 1.\n\nPlease note that the actual implementation of this feature depends on the specific AI model and the programming language you are using.\n\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n    **Score :** 0.8\n\nThis is a simple example of how you can use an AI model to compare two texts. The AI model is trained to understand the context and semantics of the text, and it can provide a similarity score between 0 and 1. The score is a measure of how similar the two texts are in terms of their content and structure.\n\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"```\n\n    **Similarity Score:** 0.7\n\n    **Response:** I'm sorry, but as an AI, I don't have the ability to respond to code reviews or provide feedback on code changes. I suggest you to review the code and provide feedback to the author.\n\nPlease note that the similarity score is a measure of how similar the two texts are in terms of content and structure. It's not a perfect measure of how similar the two texts are in terms of their actual content or functionality.\n\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n    **Similarity Score:** 0.8\n\n    **Response:**\n    **Summary:**\n    The pull request fixes a deadlock issue that was caused during the server shutdown. The deadlock was caused by the RPC server trying to write to a channel that was already closed. The fix involves running the RPC server in a separate goroutine to avoid the deadlock.\n\n    **Potential issues:**\n    - The deadlock issue could potentially be caused by the RPC server trying to write to a channel that was already closed.\n    - The server shutdown could potentially block the RPC server from writing to the channel, causing the server to hang.\n\n    **Suggestions for improvement:**\n    - Implement a mechanism to handle the case where the RPC server is already shutting down.\n    - Implement a mechanism to handle the case where the RPC server is shutting\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n    **Response:** 0.75\n\n    **Explanation:** The similarity score is a float between 0 and 1. A score of 0 means the texts are completely different, while a score of 1 means the texts are identical. In this case, the similarity score is 0.75, indicating a moderate degree of similarity between the two texts.\n\nNone\n\n    **Similarity Score:** 0.8\n\n    **Response:** I'm sorry, but as an AI, I don't have the ability to compare two PR reviews. I can only provide information and answer questions based on the data I was trained on.\n\nThis is a simple example of how you can use the similarity score to compare two texts. In a real-world scenario, you would need to use a more sophisticated method to compare the texts, such as using a machine learning model trained to understand semantic similarity.\n\nNone\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"df_sampled.to_json('pr_reviews_with_similarity_from_llm.json', orient='records', indent=4, force_ascii=False)\n# Read the file and remove escaping\nwith open('pr_reviews_with_similarity_from_llm.json', 'r') as f:\n    json_data = f.read().replace('\\\\/', '/')\n\n# Write back the cleaned JSON\nwith open('pr_reviews_with_similarity_from_llm.json', 'w') as f:\n    f.write(json_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T01:51:27.515894Z","iopub.execute_input":"2025-03-11T01:51:27.516276Z","iopub.status.idle":"2025-03-11T01:51:27.695798Z","shell.execute_reply.started":"2025-03-11T01:51:27.516246Z","shell.execute_reply":"2025-03-11T01:51:27.694780Z"}},"outputs":[],"execution_count":6}]}